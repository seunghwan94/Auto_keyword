import streamlit as st
import pandas as pd
import os

from page.login import login_page
from crawler.blog_crawler import BlogCrawler
from crawler.naver_keywords import get_naver_related_keywords
from crawler.google_keywords import get_google_autocomplete
from utils.analyzer import extract_nouns, load_stopwords, remove_stopwords, rank_keywords

from page.deluxe import deluxe_mune, deluxe_main
from page.premium import premium

st.set_page_config(page_title="SEO í‚¤ì›Œë“œ ë¶„ì„ê¸°", layout="wide")

# ë¡œê·¸ì¸ ì²˜ë¦¬
if "authenticated" not in st.session_state:
    login_page()
    st.stop()

# ë“±ê¸‰ í”Œëœ í‘œì‹œ
plan_grade = st.session_state.get("user_grade", 1)
plan_name = {1: "ğŸŸ¢ STANDARD", 2: "ğŸ”µ DELUXE", 3: "ğŸŸ£ PREMIUM"}.get(plan_grade, "ğŸŸ¢ STANDARD")
st.sidebar.success(f"ë¡œê·¸ì¸ë¨: {st.session_state['user_email']}\në“±ê¸‰: {plan_name}")

# DELUXE í”Œëœ ì„¤ì • ì…ë ¥
if plan_grade in [2, 3]:
    deluxe_mune()

# ë¶„ì„ í‚¤ì›Œë“œ ì…ë ¥
st.title(f"{plan_name} í‚¤ì›Œë“œ ë¶„ì„ê¸°")
keyword = st.text_input("ë¶„ì„í•  ì£¼ì œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë‹¤ì´ì–´íŠ¸ ì‹ë‹¨):", "")

if keyword:
    st.info(f"'{keyword}' ê´€ë ¨ ë¸”ë¡œê·¸ ë³¸ë¬¸ê³¼ ì—°ê´€ê²€ìƒ‰ì–´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

    with st.spinner("ğŸ“¦ ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
        crawler = BlogCrawler()
        naver_posts = crawler.crawl_naver_blogs(keyword, max_posts=5)
        tistory_posts = crawler.crawl_tistory_blogs(keyword, max_posts=5)
        all_posts = [p for p in (naver_posts + tistory_posts) if p]
        full_text = "\n".join([p["content"] for p in all_posts])

        related_naver = get_naver_related_keywords(keyword)
        related_google = get_google_autocomplete(keyword)
        related_text = " ".join(related_naver + related_google)

    # ëª…ì‚¬ ì¶”ì¶œ ë° ë­í‚¹
    total_text = full_text + " " + related_text
    nouns = extract_nouns(total_text)
    stopwords = load_stopwords()
    filtered = remove_stopwords(nouns, stopwords)
    ranked_keywords = rank_keywords(filtered, top_n=30)

    # ğŸ“Š í‚¤ì›Œë“œ ë­í‚¹
    df_keywords = pd.DataFrame(ranked_keywords, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„ìˆ˜"])
    st.subheader("ğŸ“Š í‚¤ì›Œë“œ ë­í‚¹ TOP 30")
    st.table(df_keywords)

    # DELUXE ì´ìƒ: ë„¤ì´ë²„ í†µê³„ ì¶œë ¥
    keyword_stats_df = pd.DataFrame()

    if plan_grade >= 2:
        keyword_stats_df = deluxe_main(keyword)
    else:
        st.warning("ğŸ”’ Deluxe, Premium ê²€ìƒ‰ëŸ‰/ê²½ìŸë„ ë¶„ì„ ê¸°ëŠ¥ì„ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # ë¶€ê°€ ì •ë³´ (ì—°ê´€ê²€ìƒ‰ì–´ & ë¸”ë¡œê·¸ ë¯¸ë¦¬ë³´ê¸°)
    with st.expander("ğŸ§© ì—°ê´€ê²€ìƒ‰ì–´"):
        st.markdown("**ë„¤ì´ë²„:**")
        st.write(", ".join(related_naver))
        st.markdown("**êµ¬ê¸€:**")
        st.write(", ".join(related_google))

    # PREMIUM: ì¶”ì²œ í‚¤ì›Œë“œ
    if plan_grade == 3 and not df_keywords.empty and not keyword_stats_df.empty:
        premium(df_keywords, keyword_stats_df, related_naver, related_google)


    with st.expander("ğŸ“° ë¸”ë¡œê·¸ ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°"):
        for post in all_posts:
            st.markdown(f"**[{post['source'].upper()}] {post['title']}**")
            st.caption(post["url"])
            st.write(post["content"][:300] + "...")
else:
    st.warning("ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
